{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required modules\n",
    "from zipfile import ZipFile\n",
    "  \n",
    "# specifying the zip file name\n",
    "file_name = \"iRSVPred_data.zip\"\n",
    "  \n",
    "# opening the zip file in READ mode\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "    # printing all the contents of the zip file\n",
    "    zip.printdir()\n",
    "  \n",
    "    # extracting all the files\n",
    "    print('Extracting all the files now...')\n",
    "    zip.extractall()\n",
    "\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dropout, Flatten,Activation, Dense, GlobalMaxPool2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "def VGG(seed = None):\n",
    "    np.random.seed(seed)\n",
    "    vgg16 = VGG16(weights=\"imagenet\", include_top=False)\n",
    "    for layer in vgg16.layers[:13]:\n",
    "        layer.trainable = False\n",
    "    for layer in vgg16.layers[13:]:\n",
    "        layer.trainable = True\n",
    "    y = (vgg16.get_layer(\"block4_conv3\")).output\n",
    "    mx_y = GlobalMaxPool2D()(y)\n",
    "    x = BatchNormalization()(mx_y)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(1024, activation='relu', name=\"dense_1024\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    preds = Dense(11,activation='softmax')(x)\n",
    "    model = Model(inputs=vgg16.input, outputs=preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "# expected data structure inside folder: train, test, val. in each folder: one folder for each class,\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, \n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"CREATE & TRAIN MODELS\"\"\"\n",
    "\n",
    "model_vgg = VGG()\n",
    "epochs = 50\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model_vgg.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_vgg.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "model_vgg.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "# save model weights\n",
    "model_vgg.save_weights(\"VGG16_weights_basmati_final.h5\")\n",
    "model_vgg.save(\"VGG16_model_basmati_final.h5\")\n",
    "\n",
    "\"\"\"EVALUATE PERFORMANCE ON THE TEST SET\"\"\"\n",
    "\n",
    "y_test = test_set_V2.classes\n",
    "pred = np.argmax(model_vgg.predict_generator(test_set_V2, steps = test_set_V2.n), axis=1)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS-VGG19\n",
    "\n",
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "def VGG(seed = None):\n",
    "    np.random.seed(seed)\n",
    "    vgg19 = VGG19(weights=\"imagenet\", include_top=False)\n",
    "    for layer in vgg19.layers[:17]:\n",
    "        layer.trainable = False\n",
    "    for layer in vgg19.layers[17:]:\n",
    "        layer.trainable = True\n",
    "    y = (vgg19.get_layer(\"block5_conv2\")).output\n",
    "    mx_y = GlobalMaxPool2D()(y)\n",
    "    x = BatchNormalization()(mx_y)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(1024, activation='relu', name=\"dense_1024\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    preds = Dense(11,activation='softmax')(x)\n",
    "    model = Model(inputs=vgg19.input, outputs=preds)\n",
    "    return model\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "# specify image data generator with data augmentation (train_datagen) resp. without (no_DA_IDG)\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0,\n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"CREATE & TRAIN MODELS\"\"\"\n",
    "model_vgg = VGG()\n",
    "\n",
    "epochs = 50\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model_vgg.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_vgg.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "model_vgg.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "# save model weights\n",
    "model_vgg.save_weights(\"VGG19_weights_basmati_final.h5\")\n",
    "model_vgg.save(\"VGG19_model_basmati_final.h5\")\n",
    "\n",
    "\"\"\"EVALUATE PERFORMANCE ON THE TEST SET\"\"\"\n",
    "\n",
    "y_test = test_set_V2.classes\n",
    "pred = np.argmax(model_vgg.predict_generator(test_set_V2, steps = test_set_V2.n), axis=1)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS--RESNET50\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "def R50(seed = None):\n",
    "    np.random.seed(seed)\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "    for layer in base_model.layers[:86]:\n",
    "        layer.trainable = False\n",
    "    for layer in base_model.layers[86:]:\n",
    "        layer.trainable = True\n",
    "    x = (base_model.get_layer(\"conv4_block1_0_conv\")).output\n",
    "    mx = GlobalMaxPool2D()(x)\n",
    "    x = BatchNormalization()(mx)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(1024, activation='relu', name=\"dense_1024\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    preds = Dense(11,activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=preds)\n",
    "    return model\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, \n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"CREATE & TRAIN MODELS\"\"\"\n",
    "\n",
    "model_r50 = R50()\n",
    "\n",
    "epochs = 50\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model_r50.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_r50.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "model_r50.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "# save model weights\n",
    "model_r50.save_weights(\"R50_weights_basmati_final.h5\")\n",
    "model_r50.save(\"R50_model_basmati_final.h5\")\n",
    "\n",
    "\"\"\"EVALUATE PERFORMANCE ON THE TEST SET\"\"\"\n",
    "\n",
    "y_test = test_set_V2.classes\n",
    "pred = np.argmax(model_r50.predict_generator(test_set_V2, steps = test_set_V2.n), axis=1)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS-XceptionNet\n",
    "\n",
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "def xcep(seed = None):\n",
    "    np.random.seed(seed)\n",
    "    Xcep = Xception(weights=\"imagenet\", include_top=False)\n",
    "    for layer in Xcep.layers[:36]:\n",
    "        layer.trainable = False\n",
    "    for layer in Xcep.layers[36:]:\n",
    "        layer.trainable = True\n",
    "    y = (Xcep.get_layer(\"block5_sepconv1\")).output\n",
    "    mx_y = GlobalMaxPool2D()(y)\n",
    "    x = BatchNormalization()(mx_y)\n",
    "    x = Dropout(.5)(x)\n",
    "    x = Dense(1024, activation='relu', name=\"dense_1024\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(.5)(x)\n",
    "    preds = Dense(11,activation='softmax')(x)\n",
    "    model = Model(inputs=Xcep.input, outputs=preds)\n",
    "    return model\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "\n",
    "# specify image data generator with data augmentation (train_datagen) resp. without (no_DA_IDG)\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, # occasionally out of range\n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224), # typical imagenet dimensions\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "validation_set =  no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"CREATE & TRAIN MODELS\"\"\"\n",
    "\n",
    "model_xcep = xcep()\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model_xcep.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_xcep.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "model_xcep.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "# save model weights\n",
    "\n",
    "model_xcep.save_weights(\"Xcep_weights_basmati_final.h5\")\n",
    "model_xcep.save(\"Xcep_model_basmati_final.h5\")\n",
    "\"\"\"EVALUATE PERFORMANCE ON THE TEST SET\"\"\"\n",
    "\n",
    "y_test = test_set_V2.classes\n",
    "pred = np.argmax(model_xcep.predict_generator(test_set_V2, steps = test_set_V2.n), axis=1)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODELS-effecient_net\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, MobileNetV2, densenet, inception_v3, efficientnet, inception_resnet_v2\n",
    "\n",
    "# import stuff \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import tensorflow_hub as hub\n",
    "#from keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, MobileNetV2\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as prepro_res50\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as prepro_vgg19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout, MaxPool2D, MaxPooling2D\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, GlobalMaxPool2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, MobileNetV2\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "\n",
    "print('Loading EfficientNetB0 ...')\n",
    "\n",
    "base_model = efficientnet.EfficientNetB0(input_shape=(224, 224, 3),\n",
    "                   include_top=False,\n",
    "                   weights='imagenet')\n",
    "\n",
    "print('EfficientNetB0 loaded')\n",
    "base_model.trainable = False\n",
    "num_classes = 11  \n",
    "x = GlobalMaxPool2D()(base_model.output)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(.5)(x)\n",
    "x = Dense(1024, activation='relu', name=\"dense_1024\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(.5)(x)\n",
    "preds = Dense(11,activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "\n",
    "# specify image data generator with data augmentation (train_datagen) resp. without (no_DA_IDG)\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0,\n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"CREATE & TRAIN MODELS\"\"\"\n",
    "model_EfficientNetB0 = model\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model_EfficientNetB0.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_EfficientNetB0.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "opt = Adam(learning_rate=1e-5)\n",
    "model_EfficientNetB0.fit_generator(generator=training_set, epochs=epochs, validation_data=validation_set, verbose=1)\n",
    "\n",
    "# save model weights\n",
    "model_EfficientNetB0.save_weights(\"EfficientNetB0_weights_basmati_final.h5\")\n",
    "model_EfficientNetB0.save(\"EfficientNetB0_model_basmati_final.h5\")\n",
    "\n",
    "\n",
    "\"\"\"EVALUATE PERFORMANCE ON THE TEST SET\"\"\"\n",
    "\n",
    "y_test = test_set_V2.classes\n",
    "pred = np.argmax(model_EfficientNetB0.predict_generator(test_set_V2, steps = test_set_V2.n), axis=1)\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####HDFF model\n",
    "##Resnet, effecient-net, VGG-16, VGG-19\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, # occasionally out of range\n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224), # typical imagenet dimensions\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "\n",
    "training_set_V2 =  no_DA_IDG.flow_from_directory(path+\"train/\", ### TO USE FOR FEATURE EXTRACTION\n",
    "                                                target_size=(224, 224), # typical imagenet dimensions\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical', shuffle=False)\n",
    "\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "validation_set_V2 = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"Loading Models & their respective weights\"\"\"\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "# save model weights for desired models of your choice\n",
    "model_vgg = load_model('VGG16_model_basmati_final.h5') \n",
    "#model_xcep = load_model('Xcep_model_basmati_final.h5')\n",
    "model_vgg19 = load_model('VGG19_model_basmati_final.h5') \n",
    "model_res50 = load_model('R50_model_basmati_final.h5')\n",
    "model_effecientNet= load_model('EfficientNetB0_model_basmati_final.h5')\n",
    "\n",
    "model_vgg.load_weights(\"VGG16_weights_basmati_final.h5\")\n",
    "model_vgg19.load_weights(\"VGG19_weights_basmati_final.h5\")\n",
    "#model_xcep.load_weights(\"Xcep_weights_basmati_final.h5\")\n",
    "model_res50.load_weights(\"R50_weights_basmati_final.h5\")\n",
    "model_effecientNet.load_weights('EfficientNetB0_weights_basmati_final.h5')\n",
    "\n",
    "\"\"\"MODEL COMBINATION\"\"\"\n",
    "\n",
    "vgg_extractor = Model(inputs=model_vgg.input, outputs=model_vgg.get_layer(\"dense_1024\").output)\n",
    "#xcep_extractor = Model(inputs=model_xcep.input, outputs=model_xcep.get_layer(\"dense_1024\").output)\n",
    "vgg19_extractor = Model(inputs=model_vgg19.input, outputs=model_vgg19.get_layer(\"dense_1024\").output)\n",
    "r50_extractor = Model(inputs=model_res50.input, outputs=model_res50.get_layer(\"dense_1024\").output)\n",
    "effecientNet_extractor =Model(inputs=model_effecientNet.input, outputs=model_effecientNet.get_layer(\"dense_1024\").output)\n",
    "\n",
    "y_train = to_categorical(training_set_V2.classes)\n",
    "X_train_m1 = vgg_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "# X_train_m2 = xcep_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "X_train_m2 = effecientNet_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "X_train_m3 = vgg19_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "X_train_m4 = r50_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "X_train = np.concatenate([X_train_m1, X_train_m2, X_train_m3, X_train_m4], axis=1)\n",
    "y_val = to_categorical(validation_set_V2.classes)\n",
    "X_val_m1 = vgg_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "#X_val_m2 = xcep_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m2 = effecientNet_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m3 = vgg19_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m4 = r50_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val = np.concatenate([X_val_m1, X_val_m2, X_val_m3, X_val_m4], axis=1)\n",
    "y_test = to_categorical(test_set_V2.classes)\n",
    "X_test_m1 = vgg_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "#X_test_m2 = xcep_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m2 = effecientNet_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m3 = vgg19_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m4 = r50_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test = np.concatenate([X_test_m1, X_test_m2, X_test_m3, X_test_m4], axis=1)\n",
    "\n",
    "\"\"\"TRAIN & TEST FEATURE EXTRACTION MODEL\"\"\"\n",
    "np.random.seed(668)\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.5, input_shape=(4096,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(11, activation=\"softmax\"))\n",
    "model1=model\n",
    "\n",
    "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "epochs = 200\n",
    "history1=model1.fit(X_train, y_train, batch_size=16, epochs=epochs, verbose=2, shuffle=True, validation_data=(X_val, y_val))\n",
    "\n",
    "\"\"\"EVALUATE MODEL ON TEST DATA\"\"\"\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "pred = np.argmax(model1.predict(X_test), axis=1)\n",
    "model1.save('model_vgg16_vgg19_Res50_effecient.h5')\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####HDFF model\n",
    "##Resnet, xception-net, VGG-16, VGG-19\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "\"\"\"LOAD DATA\"\"\"\n",
    "# path to folder with data\n",
    "path = \"\"\n",
    "\n",
    "train_datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                                   rotation_range = 5, fill_mode=\"nearest\",\n",
    "                                   zoom_range=[1/1.0, 1/1.0], width_shift_range=0.0, height_shift_range=0.0, # occasionally out of range\n",
    "                                   horizontal_flip = True, vertical_flip=True,\n",
    "                                   brightness_range=[0.5, 1.3], channel_shift_range=20)\n",
    "\n",
    "no_DA_IDG = ImageDataGenerator()\n",
    "\n",
    "# in training set: use data augmentation image data generator, for validation and test: no data augmentation.\n",
    "training_set = train_datagen.flow_from_directory(path+\"train/\",\n",
    "                                                target_size=(224, 224), # typical imagenet dimensions\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical', shuffle=True)\n",
    "\n",
    "training_set_V2 =  no_DA_IDG.flow_from_directory(path+\"train/\", ### TO USE FOR FEATURE EXTRACTION\n",
    "                                                target_size=(224, 224), # typical imagenet dimensions\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical', shuffle=False)\n",
    "\n",
    "validation_set = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=True)\n",
    "\n",
    "validation_set_V2 = no_DA_IDG.flow_from_directory(path+\"val/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "test_set_V2 = no_DA_IDG.flow_from_directory(path+\"test/\",\n",
    "                                                target_size=(224, 224),\n",
    "                                                color_mode='rgb',\n",
    "                                                batch_size=1,\n",
    "                                                class_mode='categorical',\n",
    "                                                shuffle=False)\n",
    "\n",
    "###############################################################################################\n",
    "\"\"\"Loading Models & their respective weights\"\"\"\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "# save model weights\n",
    "\n",
    "\n",
    "model_vgg = load_model('VGG16_model_basmati_final.h5') \n",
    "model_xcep = load_model('Xcep_model_basmati_final.h5')\n",
    "model_vgg19 = load_model('VGG19_model_basmati_final.h5') \n",
    "model_res50 = load_model('R50_model_basmati_final.h5')\n",
    "#model_effecientNet= load_model('EfficientNetB0_model_basmati_final.h5')\n",
    "\n",
    "model_xcep.load_weights(\"Xcep_weights_basmati_final.h5\")\n",
    "model_vgg.load_weights(\"VGG16_weights_basmati_final.h5\")\n",
    "model_res50.load_weights(\"R50_weights_basmati_final.h5\")\n",
    "model_vgg19.load_weights(\"VGG19_weights_basmati_final.h5\")\n",
    "#model_effecientNet.load_weights('EfficientNetB0_weights_basmati_final.h5')\n",
    "print(\"rakesh1\")\n",
    "\n",
    "\n",
    "\"\"\"MODEL COMBINATION\"\"\"\n",
    "\n",
    "vgg_extractor = Model(inputs=model_vgg.input, outputs=model_vgg.get_layer(\"dense_1024\").output)\n",
    "xcep_extractor = Model(inputs=model_xcep.input, outputs=model_xcep.get_layer(\"dense_1024\").output)\n",
    "vgg19_extractor = Model(inputs=model_vgg19.input, outputs=model_vgg19.get_layer(\"dense_1024\").output)\n",
    "r50_extractor = Model(inputs=model_res50.input, outputs=model_res50.get_layer(\"dense_1024\").output)\n",
    "#effecientNet_extractor =Model(inputs=model_effecientNet.input, outputs=model_effecientNet.get_layer(\"dense_1024\").output)\n",
    "\n",
    "\n",
    "y_train = to_categorical(training_set_V2.classes)\n",
    "\n",
    "X_train_m1 = vgg_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "\n",
    "X_train_m2 = xcep_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "#X_train_m2 = effecientNet_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "\n",
    "X_train_m3 = vgg19_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "\n",
    "X_train_m4 = r50_extractor.predict_generator(training_set_V2, steps = training_set_V2.n)\n",
    "\n",
    "X_train = np.concatenate([X_train_m1, X_train_m2, X_train_m3, X_train_m4], axis=1)\n",
    "\n",
    "y_val = to_categorical(validation_set_V2.classes)\n",
    "X_val_m1 = vgg_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m2 = xcep_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "#X_val_m2 = effecientNet_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m3 = vgg19_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val_m4 = r50_extractor.predict_generator(validation_set_V2, steps = validation_set_V2.n)\n",
    "X_val = np.concatenate([X_val_m1, X_val_m2, X_val_m3, X_val_m4], axis=1)\n",
    "\n",
    "y_test = to_categorical(test_set_V2.classes)\n",
    "X_test_m1 = vgg_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m2 = xcep_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "#X_test_m2 = effecientNet_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m3 = vgg19_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test_m4 = r50_extractor.predict_generator(test_set_V2, steps = test_set_V2.n)\n",
    "X_test = np.concatenate([X_test_m1, X_test_m2, X_test_m3, X_test_m4], axis=1)\n",
    "\n",
    "\n",
    "\"\"\"TRAIN & TEST FEATURE EXTRACTION MODEL\"\"\"\n",
    "\n",
    "np.random.seed(668)\n",
    "\n",
    "opt = Adam(learning_rate=1e-3)\n",
    "model = Sequential()\n",
    "model.add(Dropout(0.5, input_shape=(4096,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(11, activation=\"softmax\"))\n",
    "model1=model\n",
    "\n",
    "model1.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "epochs = 200\n",
    "history1=model1.fit(X_train, y_train, batch_size=16, epochs=epochs, verbose=2, shuffle=True, validation_data=(X_val, y_val))\n",
    "\n",
    "\"\"\"EVALUATE MODEL ON TEST DATA\"\"\"\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "pred = np.argmax(model1.predict(X_test), axis=1)\n",
    "model1.save('model_vgg16_vgg19_Res50_xcep.h5')\n",
    "print(accuracy_score(y_test, pred))\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
